								\chapter{Solution Search}

\section{General A.I. Search}

Artificial Intelligence Search is a general class of algorithms that discover (or ``search'' for) plans that turn a start state into a goal state. The plan produced is a sequence of actions that, if taken, will obtain a goal state.

	\subsection{State Space Formulation}

The ``state'' is defined as a set of information that minimally represents the current progress to the goal. The state is transformed by actions available to the agent. The successor function is responsible for transforming a state and action into a successor state.

Other parts of the problem that are not time-variant are considered part of the environment.

	\subsection{State Space Size}
The size of the state space is all possible valid combinations of the components of the state space. For a positional search problem on an $M$ by $N$ grid with one agent, the size of the state space is $MN$. For two players, it would be $(MN)^2$.

As the size of the state space expands, it can have disastrous consequences on the effectiveness of a search problem. General A.I. Search is effective at finding solutions in state spaces that are manageable; if the state space becomes too expansive, the search algorithms have to enumerate through far too many possibilities to make progress towards a goal. This prevents the search from terminating in a reasonable amount of time.

	\subsection{State Space Exploration}

Exploration of a state space happens through a transition function that generates successor states from state action pairs. The transition function commonly contains all the ``environment'' information and validation checks -- for example in a positional search problem, the transition function would contain the list of walls and prevent the agent from moving into a wall.

\section{Adaption of A.I. Search}

The A.I. Search algorithms in this paper will be unmodified versions of those found in popular literature, but our approach to the state space approach will be quite different.

	\subsection{Traditional Formulation}

The traditional state formulation for kinematic problems is to define the state of a particle as it's currrent position, velocity, and acceleration. The actions available to the agent at any time are usually actions that change the acceleration on the particle. The successor function integrates this kinematic state in time with a pre-defined accuracy.

The problem with this type of state formulation is that the state space becomes far too expansive for the majority of problems. Even in the reduced problem where there are 100 possible position, velocity, and acceleration vectors, the state space is $100^3$. This presents far too many possible states for search algorithms to enumerate, and it produces an unbearable computational load.

Because of this, general A.I. search is rarely used in kinematics problems -- other techniques like kinematical planning are more common.

	\subsection{Our State Formulation}

Our state formulation overcomes these difficulties by drastically reducing the size of the state space. We instead transition most of the computational overhead to the transition function.

We define our state as the ``settled'' position of the particle, meaning the state is either:

\begin{enumerate}
\item The concave vertex the particle is resting in, or
\item outside of the workpiece.
\end{enumerate}

By defining our state this way, we dramatically reduce the size of the state space to
$$
num(V_{cc}) + 1
$$
where $V_{cc}$ is defined as the set of concave vertices in the workpiece.

Because the maximum number of states visited is now only linear in concave vertices, our search algorithms have far fewer states to expand and a reduced computational load.

	\subsection{Exploration}

The bulk of the computational work will now be in the transition function. The transition function will be responsible for producing the set of concave vertices ``reachable'' from the current concave vertex from the available actions.

\section{Transition Function}

The transition function produces successor states from a set of available actions and initial state. For our problem, this means that the transition function will produce the set of concave vertices (or workpiece exit status) ``reachable'' from a given arbitrary concave vertex.

The actions available to the agent will represent the possible gravity directions from a given concave vertex. These gravity directions can be obtained by rotating the workpiece; in this sense, a given gravity direction must be obtained by rotating a starting gravity direction to the desired direction.

	\subsection{Sampling}

The transition function will sample from the available set of gravity vectors and produce a desired ``turn.'' A turn of the workpiece results in the gravity vector sweeping from $g_{start}$ to $g_{end}$ over a time $t_{turn}$. During this turn, the particle's path is simulated. After the turn, the particle is simulated over time until it settles in a new concave vertex or exits the workpiece.

In this sense, one can think of the transition function as taking in a concave vertex and producing a set of ``reachable'' concave vertices:

$$
trans(V_{cc}^{i}) = \left \{ V_{cc}^{1}, V_{cc}^{2}, ...  \right \}
$$

	\subsection{Limits of Sampling}

In this paper, we restrict the possible gravity directions available from a concave vertex. The primary reason for this is based on our simulation -- if a shift in gravity causes a particle to leave the surface while the workpiece is still rotating, we cannot simulate that part of the path efficiently. For this reason, we throw out the possible gravity vectors that cause this type of particle movement to happen.

The first set gravity vectors we exclude are any vectors that don't cause the particle to leave the concave vertex. These vectors result in no state change and can be ignored.

The second set of gravity vectors that are excluded are those that cause the particle to fall off the leading edge out of a concave vertex.

\myfigure{transitionfunctionsampling}{The possible range of gravity vectors to sample from.}

This leaves two arcs of gravity vectors. The bounds on each arc are defined by the minimal gravity vector to produce movement out of the concave vertex ($g_{\epsilon}$) and the maximum gravity vector to keep the particle on the surface ($g_{max}$).

	\subsection{Ideal Transition Function}

The ideal transition function produces the maximum set of ``reachable'' concave vertices while minimizing the necessary computation. In order to do this, the transition function must construct a number of starting kinetic states for the particle and simulate where the particle settles.

	\subsection{Representative Coverage Between Limits}

Because each arc of gravity vectors is a range, there are an infinite number of samples to extract. This means that our transition function must enumerate an infinite number of possibilities to get full confidence that the set of ``reachable'' concave vertices has been achieved.

To reduce our computational load, we will instead choose a set of gravity vectors that produces a reasonable coverage over the possible types of kinetic paths achieved. Because our goal is to produce the maximum number of reachable concave vertices, we will choose a sampling method that produces the most diverse set of kinetic paths.

If the possible range of samples is from $0$ to $1$, a fairly reasonable sample function was to use $x^3$. Because the acceleration effects compound with time, uniform sampling produced far too many high-velocity kinetic paths. A cubed sampling produced a more even coverage of kinetic paths.

\myfigure{samplingUniform}{The range of kinetic paths produced from 10 samples at uniform sampling.}

\myfigure{samplingCubed}{The range of kinetic paths produced from 10 samples at cubed sampling. Note the resulting kinetic paths evenly cover the space after the leading edge.}

With this sampling function, we can obtain better coverage with lower computational cost.

	\subsection{Graph Search}

To further increase computational efficiency, we implement two types of graph reduction in our search.

The first is by using the standard Graph implementation of our A.I. Search Algorithm. This graph version of the algorithm prevents a state from being expanded twice. Because the connectivity graph within workpieces often has a lot of cycles, preventing more than one expansion at each state helps considerably in cutting down computational cost.

The second graph reduction is in the transition function. When the transition function samples in both directions and receives a list of concave vertices that are ``reachable,'' it reduces that list down to a set. The reduction is based on cost-priority (where the lower-cost plans to reach a concave vertex are chosen over higher-cost plans). This graph reduction puts fewer plans on the fringe, reducing the memory overhead.

In workpieces with finely-tesselated concave sections, the connectivity graph is highly connected and contains many cycles. These two graph reductions improve performance dramatically.

\myfigure{hemisphereSection}{A finely-tesselated concave section. The draining graph for a workpiece like this is highly connected and cyclic.}

\section{Search}

Now that our state formulation and transition function is fully defined, we can then use a standard A.I. Search algorithm to expand out from a start state to a goal state.

	\subsection{Uniform Cost Search}

Our paper uses the standard implementation of uniform cost graph search to obtain a plan to he goal state. By using uniform cost search, we ensure our obtained solution is optimal in cost.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\Function{UniformCostGraphSearch}{$problem,fringe$}
	\State $closed \gets$ an empty set
	\State $fringe \gets$ INSERT(MAKE-NODE(INITIAL-STATE[$problem$]),$fringe$)

	\While{$fringe$ not empty}
		\State $node \gets$ REMOVE-FRONT($fringe$)
		\If{Goal-Test($problem$,STATE[$node$])}
			\State \textbf{return} $node$ \Comment{Success}
		\EndIf
		\If{State[$node$] not in $closed$}
			\State add State[$node$] to $closed$
			\State $fringe \gets$ InsertAllByPriority(Expand($node, problem$), $fringe$)
		\EndIf
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states}

\EndFunction

\end{algorithmic}
\end{algorithm}

	\subsection{Cost Function}

Our cost function for a given plan (sequence of turns) can be a variety of properties depending on our optimization goal.

		\subsubsection{Time}

The primary concern in manufacturing is often the processing time for a given procedure. In this case, the plans enqueued into the fringe are ordered by the total backward time to execute that plan. This ensures that when we dequeue a plan that ends in the goal, it has the lowest total time out of any plan on the fringe.

		\subsubsection{Energy}

Another popular concern in manufacturing is the energy required for a given procedure. If energy is the optimization goal, plans can be instead enqueued by the estimated total amount of energy required to execute that series of turns.


There are many ways to estimate the amount of energy required to execute a series of turns. The exact details are dependent on the fixture setup and associated motor; we present three simple models of energy estimation.

		\subsubsection{Energy - Rotation Angle}

The first estimation of energy is based on the total rotation angle. If friction in the bearings and motor are the primary energy losses for the draining process, plans can be enqueued by their total absolute angle change.

This model would be appropriate if the workpiece was well balanced in a fixture that produced high energy loss due to friction.

		\subsubsection{Energy - Workpiece Center of Gravity}

Another model for energy is based on the work the motor has to perform against gravity. If the workpiece's center of gravity is positioned far away from the center of rotation, the workpiece is unbalanced in the fixture. Turns that raise the center of gravity will produce counter-torques, will turns that lower the center of gravity will produce added acceleration.

% figure needed

If this model is more appropriate for the fixture setup, the plans can be enqueued onto the fringe based on the integrated change in height for the center of gravity.

		\subsubsection{Energy - Acceleration And Deceleration}

Finally, if the workpiece is well balanced and friction in the rotator is low, the most appropriate model may be one based on acceleration and deceleration of the workpiece. While the total number of accelerations commonly scales with the total angle, these two properties are not necessarily the same.

In this case, plans can be enqueued based on their total acceleration change.

%shitton of equations needed here

	\subsection{Solution}

		Defined as the sequence of gravity transitions from each concave vertex to produce a particle path that exits the workpiece.

\section{Control Sequence Generator}

Now that we have a solution, we need to generate a control sequence for the workpiece rotator.

	\subsection{Sample-defined Rotations}

These rotations are defined for us by the transition function.

	\subsection{Intermediary Rotations}

Between these samples we don't have anything. What we do is just interpolate between the last sample and the beginning of the next sample with a cubic bezier curve.

\section{Results}

	\subsection{Run Time}

Runs fast.

	\subsection{Part Complexity}

Transition function is constant in best case, unbounded in worst case based on the number of polygon edges.

	\subsection{Demonstration of Solution}

Go to this web address!

\section{Future Work \& Discussion}

Could be improvements

	\subsection{Heuristics for A* Search}

A* search can be added with heuristics. Distance to workpiece bounding box might be a good one, but that's essentially a radially symmetric heuristic, not very informative.
