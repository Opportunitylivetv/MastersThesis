\chapter{Extension to Multiple Particles}\label{multipleExtension}

We now present an extension of this work for draining multiple particles out of a workpiece. The initial adaption to our approach is straightforward, but the two search optimizations we present shortly afterwards dramatically improve search performance.

\section{Initial Adaption}

Only two elements of our approach need to be modified in order to drain multiple particles out of a workpiece. The first is a modification to the state definition; the state is now a set of settled locations, one for each particle:

\myequation{
  (V_{c}^{1}, V_{c}^{2}, V_{c}^{3}, ... , V_{c}^{n}).
} {
  \label{eq:multipleParticleState}
}

The second modification is to our successor function definition; the successor function now takes in a set of particle locations and produces a set of ``reachable'' states:

\myequation{
  successor((V_{c}^{1}, V_{c}^{2}, ... , V_{c}^{n})^i) = \left \{ (V_{c}^{1}, V_{c}^{2}, ... , V_{c}^{n})^1, (V_{c}^{1}, V_{c}^{2}, ... , V_{c}^{n})^2, ...  \right \}.
} {
  \label{eq:successorMultipleParticle}
}

With only these modifications alone we are now able to search for solutions that drain multiple particles out of the workpiece.

\subsection{Implementation}

These two modifications to our approach result in a fair number of changes in the implementation. One primary implementation difference is that now a given turn must be simulated across all particle locations. This simulation is usually performed by the transition function:

$$
transition(V_{c}^{i}, turn(g_{start}, g_{end}) = V_{c}^n \qquad or \qquad exit.
$$

Earlier we had restricted our action space to only turns that produced motion of the particle and kept the particle on the incident edge of the concave vertex. This means there was only one possible outcome for a turn simulation -- motion of the particle was induced, and that motion began immediately when the turn was performed.

Now that any arbitrary turn can be simulated against an arbitrary particle, this guarantee no longer holds true. Consequently, we now have four possible simulation scenarios in the transition function as described below.


\begin{itemize}
\item The particle has exited the workpiece; a turn does not change this particle's state.
\item The turn results in no motion; any linear combination between $g_{start}$ and $g_{end}$ does not produce motion of the particle.
\item Motion of the particle starts immediately when the turn begins; $g_{start}$ is a vector that produces motion.
\item Motion of the particle starts midway through the turn; $g_{start}$ does not produce motion, but as the gravity vector sweeps to $g_{end}$, motion is induced at some intermediate point.
\end{itemize}

Because of these multiple simulation scenarios, the multiple-particle version of the transition function may not make assumptions about the input turn. While not of great importance for the overall picture of the approach, this presents a significant obstacle during implementation that should be considered.

\section{Multiple Particle Time Complexity}

Now that our state is defined as a set of concave vertex locations, the state space is unfortunately exponential in the number of particles $n$:

$$
(V_{concave} + 1)^n.
$$

As in Section \ref{timeComplexity}, we would like to produce an expression that estimates the upper bound of intersection tests that must be performed during search. With the same previous assumption that each particle simulation involves $e^2$ intersection tests, our expression for the upper bound intersection tests for multiple-particle search becomes:

\myequation{
  c_1 \cdot e^2 \cdot (V_{concave})^n
} {
  \label{eq:bigoTotal}
}

Equation \eqref{eq:bigoTotal} is exponential in the number of concave vertices rather than linear as in Equation \eqref{eq:bigo}.

Although earlier we had avoided exponential state spaces and runtimes due to our search formulation, the introduction of multiple particles has yet again vastly expanded our state space. Our algorithm as presented thus far will still find solutions to these problems; unfortunately, it will take several factors of time longer to obtain solutions.

In order to improve running time of the algorithm, we present two search optimizations that significantly reduce the number of states expanded and obtain solutions much faster. These optimizations sacrifice the guarantee of optimality in exchange for an improvement in running time.

\section{Search Heuristics}

The high level goal of a search heuristic is to ``guide'' the exploration of state space towards potential solutions \cite{AIBook}. This is accomplished by either preventing the exploration of certain states or by intelligently ranking potential plans on the fringe \cite{AIBook}. If fewer states are explored before a solution is found, the algorithm's performance will improve.

Because the definition of a heuristic is quite general, there are many possible heuristics to choose from -- the space of heuristic choices is wide. We present our specific choice of a heuristic for the multiple-particle draining problem below, but many other valid (and potentially better) heuristics exist.

\section{Multiple Particle Heuristics}

The one advantage of the multiple-particle formulation of the drainability problem is that it allows for more creativity and flexibility when composing search heuristics. Previously in single-particle draining, our state was simply defined as a concave vertex location. This meant that any potential heuristic had only the workpiece geometry and a position as input variables.

Now that our state is a set of settle locations, we can instead create heuristics that operate on direct properties of the state in addition to workpiece geometry.

\subsection{Plan Ranking Heuristic}

The first search optimization (and true search heuristic) we implemented was simply a ranking of the partial plans in the priority queue during uniform cost search. Rather than ranking only by cost, we also implemented the following two ranking modifications:

\begin{itemize}
\item If the number of exited particles is not the same, prefer the plan with a higher number of exited particles regardless of cost;
\item otherwise, number of particles in the same location shall be combined with cost as the ranking key.
\end{itemize}

During our testing of the algorithm, we found that ranking potential plans by

$$
cost - 10 \cdot numSame
$$

where $numSame$ is the number of particles in the duplicate locations produced an effective mix between optimality of plans and speed of search.

With this plan ranking heuristic, our search algorithm prefers states that have a high number of particles out of the workpiece or a high number of particles in duplicate locations. Plans that fit these characteristics have an additional performance benefit; exited particles do not have to be simulated in the transition function, and each concave vertex location only has to be simulated once.

This essentially reduces the time complexity of the algorithm. If $o$ is the number of particles that have exited out of the workpiece and $m$ is the number of particles in duplicate locations, our expression from Equation \eqref{eq:bigoTotal} for the upper bound of intersection tests becomes

\myequation{
  c_1 \cdot e^2 \cdot (V_{concave})^{n -o -m}
} {
  \label{eq:bigoTotalWithHeuristic}
}

which is a factor of $(V_{concave})^{o + m}$ smaller than Equation \eqref{eq:bigoTotal}. Chapter \ref{results} provides quantitative details on the performance improvements gained from this ranking heuristic; the average speedup was approximately $1.5 \times$.

\subsection{Action Space Reduction Technique}

The second search optimization we present is centered around sampling from the action space. Recall that for a single particle, we defined our action space to sample from as a fixed pair of $g_{start}$ vectors and a range of $g_{end}$ vectors that produce motion of the particle as illustrated in Figure \ref{restriction3}. Now with multiple particles, we have multiple sets of these defined vectors as illustrated in Figure \ref{multiMinPocket}.

\myfigure{width=0.8\linewidth}{multiMinPocket}{Action Space sampling for each concave vertex.}

When sampling turns for our successor function, we may sample from any of these defined spaces. Doing so, however, presents three primary concerns as described below.

\begin{itemize}
\item This action space is fairly large and grows linearly with the number of particles in the workpiece, further increasing our algorithm's time complexity.
\item Although the set of $g_{end}$ vectors for a particular concave vertex have been reduced to keep that particular particle on the incident edge of its concave vertex, a $g_{end}$ vector from this space may cause other particles to leave the surface of the workpiece during rotation. This results in scenario \#4, which causes the sample to be rejected immediately.
\item A particular turn's $g_{start}$ may be well into the ``induce motion'' space of another concave vertex. If the workpiece were able to rotate infinitely fast to a particular orientation this would be of no concern; unfortunately, we assume finite rotation speed, which means a ``setup'' turn to this $g_{start}$ vector would induce motion of another particle. This means that our solution post-processor can no longer assume that all turns in between partial plan turns do not induce motion. Consequently, in order to accurately simulate a turn with this condition we must rotate $g_{start}$ back to the first vector that produces motion for any particle.
\end{itemize}

The second and third concerns are the primary reasons why an action space reduction technique is employed. These two concerns result in a high number of sample rejections or modifications, which leads to wasted computation.

The goal of our action space reduction technique is to find a pair of $g_{start}$ vectors that do not induce motion of \emph{any} particle. The sample space of $g_{end}$ vectors will then be defined by this pair of $g_{start}$ vectors as before.

Reducing our action space in this way resolves each of our previous concerns. First, the action space will now be a constant size regardless of the number of particles. Secondly, because the $g_{end}$ sample space is generated from a pair of $g_{start}$ vectors that do not induce motion for any particle, no $g_{end}$ vector will directly cause scenario \#4. Finally, no turn sampled from this space will induce motion of a particle immediately, meaning our solution post-processor requires no further modificaitons.

This action space reduction technique is accomplished in several steps. The first is to examine all the $g_{start}$ vectors for each concave vertex, as illustrated in Figure \ref{actionspace1}.

\myfigure{width=0.4\linewidth}{actionspace1}{$g_{start}$ vectors from each concave vertex.}

We then define a region of the Gaussian circle between each pair of $g_{start}$ vectors that does not result in particle motion. This region is referred to as the ``dead space'' for a particular concave vertex, as illustrated in Figure \ref{actionspace15}.

\myfigure{width=0.5\linewidth}{actionspace15}{The ``dead space'' for each concave vertex visualized as a shaded region of the Gaussian circle.}

By intersecting all of these ``dead space'' regions together, we can then find the total intersection region as illustrated in Figure \ref{actionspace2}.

\myfigure{width=0.8\linewidth}{actionspace2}{The intersection between all ``dead space'' regions.}

Lastly, we can then select the pair of $g_{start}$ vectors that define this region to compute our final pair of $g_{start}$ vectors as illustrated in Figure \ref{actionspace3}.

\myfigure{width=0.8\linewidth}{actionspace3}{Pair of $g_{start}$ vectors selected that do not produce motion of any particle.}

Now with a defined set of $g_{start}$ vectors, we can simply define the $g_{end}$ sample space as those vectors which keep all particles on a incident edge of the workpiece. This is simply the set of vectors that range from parallel to orthogonal from $g_{start}$:

\myfigure{width=0.8\linewidth}{actionspace4}{$g_{start}$ and $g_{end}$ vectors defined from a set of concave vertices.}

Now our action space is a function of the set of concave vertex locations; this means that our action space is always the same size, regardless of the number of particles being simulated. This greatly improves performance of the algorithm.

