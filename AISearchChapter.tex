								\chapter{Solution Search}

\section{General A.I. Search}

Artificial Intelligence search is a field of study and class of algorithms that discover (or ``search'' for) plans that turn a start state into a goal state in a deterministic world. A.I. search makes heavy use of simulation to compute solutions offline before enacting those solutions in the real world.

Based on our ability to rapidly simulate water particles and the deterministic nature of the workpiece draining problem, we choose A.I. search to discover a series of rotations that fully drains a workpiece.

	\subsection{Terminology}

In order to describe how A.I. search applies to the draining problem in manufacturing, some terminology must be defined first. In order to aid our definitions, we will use a simple positional search problem as an example, shown below.

\myfigure{width=0.7\linewidth}{robotGrid}{A small positional search problem; a robot on a $M$ by $N$ grid is attempting to reach a goal position $G_{pos}$}

The ``state'' is defined as a set of information that minimally represents the current progress to the goal. For this positional search problem, the minimal state representation would be the position tuple of the robot $(R_x,R_y)$, where $R_x$ is the horizontal position of the robot and $R_y$ is the vertical position of the robot. Here these variables can take on positive integer values up to $M$ and $N$ respectively.

For every state, the agent under control has a number of actions available to take. In our example, the robot would have the actions $North$, $South$, $East$, and $West$ available to execute.

When the agent under control takes an action, a new state is produced. The ``transition function'' is responsible for transforming a state action pair into a successor state. For example, if the robot above was in position $(M = 1, N = 2)$ and took the action $North$, the transition function would return the state $(M = 1, N = 3)$.

This transition function is also responsible for performing validity checks against the environment. In our positional search example, the transition function would be responsible for making sure the robot does not move off the grid or into a square occupied by another agent or wall. If an invalid state action pair is given to the transition function, the transition function commonly returns $null$ to designate this invalid combination.

The ``successor function'' is a meta-function that uses the transition function and available actions to the agent. It is responsible for generating a list of successor states reachable (in one action) from a given state. For the above problem, the successor function would return the list of adjacent squares the robot could move into and the actions that produce those states.

A ``plan'' is simply a sequence of actions. While reaching the goal state determines that the search algorithm has succeeded, the sequence of actions to achieve a goal state is usually the objective of the solution. Consequently, plans are usually maintained and updated by the successor function when exploring states.

	\subsection{General Tree Search}

These definitions are enough to implement the standard tree search algorithm.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\Function{TreeSearch}{$problem$}
	\State $queue \gets$ (initial state of $problem$, empty $plan$)

	\While{$queue$ not empty}
		\State $state, plan \gets$ REMOVE-FRONT($queue$)
		\If{Goal-Test($problem$,$state$)}
			\State \textbf{return} $plan$ \Comment{Success}
		\EndIf
		\State InsertAll($queue$, SuccessorFunction($state, plan$)) \Comment{Inserts a list of new states and plans into the queue}
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states on the queue}

\EndFunction

\end{algorithmic}
\end{algorithm}

	\subsection{Importance of Formulation}

The above definitions of state, actions, and successor functions are quite general. This means that there are several valid formulations (or definitions) of states for a given problem. The particular formulation chosen can have large consequences on the effectiveness of A.I. search and the algorithmic runtime.


The size of the state space is the important factor when considering different problem formulations. A state space size is defined by size of the set of the different values the state could hold.

For our example above, we define the state to be the position tuple $(R_x, R_y)$. Since $R_x$ and $R_y$ can take on positive integer values up until $M$ and $N$ respectively, the size of the set of possible state values is $MN$.

While a positional search problem with one agent does not present a large (or ``expansive'') state space, these state spaces can quickly get out of control for slightly more complex problems. For instance in the general case of $l$ agents on a board of $M$ by $N$ size, the state space is defined by the list of position tuples $(R^1_x, R^1_y), (R^2_x, R^2_y)... (R^l_x, R^l_y)$. In this case the size of the state space is all possible permutations of these variables, or $(MN)^l$.

State spaces often grow exponentially large with the addition of new variables. If the state space becomes too expansive, the effectiveness of general search algorithms can be jeopardized. This is because general A.I. search has to enumerate through (or ``process'') many different states before reaching a goal state. If there are too many states to process before reaching a goal state, the algorithm may not terminate in a reasonable amount of time.

\section{Adaption of A.I. Search}

Our work focuses on a traditional application of A.I. search to a novel state space formulation for workpiece draining. Our unique state formulation reduces the size of the state space to make it manageable for general A.I algorithms.

	\subsection{Traditional Formulation}

Rotating a water particle out of a workpiece can be considered a kinematic planning problem. Traditional kinematic planning problems often have state spaces that encode the kinematic properties of the object (or agent) being planned for \cite{kuffner2000rrt}. The most common state formulation is to encode the position, velocity, and acceleration of the agent as the state formulation.

The actions available to the agent at any time are usually actions that change the acceleration on the agent. The transition function integrates this kinematic state and acceleration change in time with a pre-defined accuracy. Consequently, many transition function calls must be made to accurately integrate the path of the agent through time.

The problem with this type of state formulation is that the state space commonly becomes far too expansive for general A.I. search algorithms. Consider a reduced problem where there are only 1000 possible position, velocity, and acceleration vectors. The size of the state space here is $1000^3$. This presents a large number of possible states for a search algorithm to enumerate through; the scale of this state space may prevent the algorithm from terminating.

Because of this, general A.I. search is rarely used in kinematics problems -- other techniques that avoid combinatorial state space ``explosion'' are more common \cite{kuffner2000rrt} \cite{yakey2001randomized} \cite{nakamura1991nonholonomic}.

	\subsection{Our State Formulation}

Our state formulation overcomes these difficulties by drastically reducing the size of the state space. We instead offload most of the computational overhead to the successor function.

The key insight here is to observe only the concave vertices of the workpiece; this insight was first used by Yasui et al. \cite{Yasui2011} in order to reduce the scope of analzying the drainability of all possible rotation axes. Here it is applied to the state space formulation for the first time in order to maintain the effectiveness of general A.I. search.

We define our state as the ``settled'' position of the particle, meaning the state is either:

\begin{enumerate}
\item The concave vertex the particle is resting in, or
\item outside of the workpiece.
\end{enumerate}

By defining our state this way, we produce a state space with size of
$$
num(V_{cc}) + 1
$$
where $V_{cc}$ is defined as the set of concave vertices in the workpiece. The size of this state space is small compared to kinetic state definitions which can be exponential in the accuracy of each value.

Because the maximum number of states visited is now only linear in concave vertices, our search algorithms have far fewer states to expand and a lower upper bound on running time.

\section{Exploration}

The bulk of the computational work will now be in the successor function, which is responsible for producing the set of states that are one ``action'' away from a given input state. If a given state $S_i$ is one action away from an input state $S_j$, we define $S_i$ to be ``reachable'' from $S_j$.

	\subsection{Successor Function}

The successor function produces the list of reachable states from a given input state. For our problem, this means that the successor function will produce the set of concave vertices (or workpiece exit status) reachable from a given arbitrary concave vertex.

$$
successor(V_{cc}^{i}) = \left \{ V_{cc}^{1}, V_{cc}^{2}, ...  \right \}
$$

	\subsection{Action Definition}

The ``actions'' available to our agent will be represented by the possible set of rotations of the workpiece over time. In this problem we choose our frame of reference to be the workpiece geometry, so the rotation of the workpiece is observed as a rotation of the gravity vector through time. This means that our action results in a change in the acceleration field.

More formally, we define one action (or ``turn'') as a sweep in the gravity vector from $g_{start}$ to $g_{end}$ over a time $t_{turn}$. The interpolation function between $g_{start}$ and $g_{end}$ could take on any form, but we restrict ourselves to linear interpolation for simplicity.

	\subsection{Transition Function}

Now we have fully defined both elements for the transition function; the states are concave vertices and the actions available to the agent are specific turns.

Consequently, the transition function is then defined as a function that takes in a concave vertex and a turn; it produces the settled state of the particle after simulation.

$$
trans(V_{cc}^{i}, turn_{l}) = V_{cc}^j \qquad or \qquad exit
$$

	\subsection{Possible set of Turns}

A turn is defined by three different variables: $g_{start}$, $g_{end}$, and $t_{turn}$. These variables could take on many values which means many different turns could be produced. Consequently, a large number of actions are available to the agent at any given state, which leads to computational explosion (yet again).


In this work, we restrict the possible set of ``turns'' from a given concave vertex to reasonable limits. The main way this is accomplished is by reducing the set of gravity vectors available and fixing the duration of the turn. By doing so we reduce the space of all possible actions to something ``manageable'' which still represents the full range of kinetic possibilities. An action or state space is ``manageable'' if it does not jeopardize termination of the algorithm.


To understand how the set of gravity vectors is reduced, some terminology must first be defined. A given concave vertex has two leading edges $E_1$ and $E_2$ defined by outward vectors $\vec{e}_1$ and $\vec{e}_2$.

\myfigure{width=0.5\linewidth}{edgeDefinition}{A concave vertex $V_{cc}^1$ and its two corresponding outward edge vectors $\vec{e}_1$ and $\vec{e}_2$}

We start with a full sphere of possibilities to sample $g_{start}$ and $g_{end}$ from, as shown below:

\myfigure{width=0.8\linewidth}{restriction1}{The initial set of possible vectors to sample $g_{start}$ and $g_{end}$ from.}

We first restrict the possible values of $g_{start}$. We would like $g_{start}$ to be a vector that does not induce motion of the particle; this ensures a turn that ends in $g_{start}$ does not require simulation once the turn ends. Simultaneously, we would also like any defined turn to spend the maximum amount of time inducing motion of the particle.

This means that $g_{start}$ is a vector that does not produce motion of the particle but is as close as possible to producing motion. There are only two vectors that satisfy these conditions -- the perpendicular vectors to $\vec{e}_1$ and $\vec{e}_2$.

\myfigure{width=0.8\linewidth}{restriction2}{$g_{start}$ is reduced to one of the two perpendicular vectors}

Our second restriction is that $g_{end}$ must be a vector that produces motion of the particle while simultaneously keeping the particle on the leading edge of the concave vertex. This produces two quarter-circle segments of possibilities for $g_{end}$, each of which are defined by a leading edge and the perpendicular vector to that edge.


\myfigure{width=0.8\linewidth}{restriction3}{$g_{end}$ is reduced to vectors that produce motion while keeping the particle on the leading edge}

This leaves two arcs of gravity vectors from which $g_{end}$ can be selected.

	\subsection{Ideal Successor Function}

The ideal successor function produces the maximum set of ``reachable'' concave vertices from a given input concave vertex (and the actions to achieve those states).

Unfortunately, there are an infinite number of turns possible from each concave vertex, for $g_{end}$ can be selected from a continuous range of vectors. Clearly enumerating through every possible turn at every concave vertex is not possible.

	\subsection{Sampling}

To overcome this difficulty, we will instead sample from the continuous range of $g_{end}$ vectors and produce a limited number of turns. Each sample from this $g_{end}$ space produces a turn, which can be simulated with our transition function to produce a settled state.

Sampling from this space produces a list of defined turns (or actions). Our successor function will then examine these actions in conjunction with an input concave vertex and produce the set of reachable concave vertices.

Ideally this set of concave vertices produced by sampling would be identical to the set achieved by the full enumeration of the sampling space. This is not likely to happen in practice, but with careful design we can discover the majority of this set.

	\subsection{Representative Coverage Between Limits}

The way we produce the majority of this set is to obtain a representative coverage over the possible kinetic paths out of a concave vertex. This is done by choosing a sampling method that produces the most diverse set of kinetic paths.

If the possible range of $g_{end}$ vectors is defined between the limits of $0$ and $1$, then an initial best-guess sampling function may be to use uniform sampling in the form of $x$. Because acceleration effects compound with time however, this uniform sampling method produces many kinetic paths that are almost identical as can be seen below.

\myfigure{width=0.5\linewidth}{samplingUniform}{The range of kinetic paths produced from 10 samples from each side at uniform sampling. Many of the sampled kinetic paths are nearly identical and thus visually appear as one.}

A far better sampling function is to use $x^3$. This function produces many samples at the low end of the range of $g_{end}$ vectors and only a few at the higher end. These low-end samples produce accelerations that are minimally different, but since acceleration effects compound with time, they produce drastically different kinetic paths as can be seen below.

\myfigure{width=0.5\linewidth}{samplingCubed}{The range of kinetic paths produced from 10 samples at cubed sampling. Note the resulting kinetic paths evenly cover the space after the leading edge.}

With this sampling function, we can obtain better coverage with lower computational cost.

	\section{Complete Formulation}

Now we have all the pieces to implement A.I. search. Our state is defined as the concave vertex the particle rests in (or workpiece exit). Our successor function samples from an available range of actions to produce a reasonable set of reachable concave vertices. Simply combining these two definitions together can produce an algorithm that discovers a sequence of actions to rotate a water particle out of a workpiece.

	\subsection{Graph Search}

To further increase computational efficiency, we implement two types of graph reduction in our search.

The first is by using the standard graph implementation of our search algorithm. This graph version of the algorithm prevents a state from being expanded twice. Because the connectivity graph within workpieces often has many cycles \cite{Yasui2011}, preventing more than one expansion at each state helps considerably in cutting down computational cost.

Note how the following algorithm is similar to tree search but makes use of a closed set.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\Function{UniformCostGraphSearch}{$problem,fringe$}
	\State $closed \gets$ an empty set
	\State $fringe \gets$ INSERT(MAKE-NODE(INITIAL-STATE[$problem$]),$fringe$)

	\While{$fringe$ not empty}
		\State $node \gets$ REMOVE-FRONT($fringe$)
		\If{Goal-Test($problem$,STATE[$node$])}
			\State \textbf{return} $node$ \Comment{Success}
		\EndIf
		\If{State[$node$] not in $closed$}
			\State add State[$node$] to $closed$
			\State $fringe \gets$ InsertAllByPriority(Expand($node, problem$), $fringe$)
		\EndIf
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states}

\EndFunction

\end{algorithmic}
\end{algorithm}

The second graph reduction is implemented directly in the successor function. When the successor function enumerates through the list of samples from the possible turns, it maintains a cost-sensitive closed set of concave vertices that are reachable. This set is keyed based on the ``cost'' of a transition, which in most cases is defined as the duration of the simulation.

By doing so, our successor function produces the optimal reduced set of concave vertices reachable from a given state. This graph reduction enqueues fewer plans onto the fringe, reducing the memory overhead and improving performance.

These two graph reductions excel in workpieces with finely-tesselated concave sections. Here the connectivity graph is highly connected and contains many cycles. Without graph reductions, tree search would spend a considerable amount of time expanding all the concave vertices multiple times.

\myfigure{width=0.5\linewidth}{hemisphereSection}{A tesselated concave section. The draining graph for a workpiece like this is highly connected and cyclic.}

\section{Cost}

The uniform cost graph search algorithm we use ensures the plan produced is optimal in cost. Our definition of cost however is very flexible and can be modified according to different manufacturing priorities.

		\subsubsection{Time}

The primary concern in manufacturing is often the processing time for a given procedure. In this case, the plans enqueued into the fringe are ordered by the total backward time to execute that plan. This ensures that when we dequeue a plan that ends in the goal, it has the lowest total time out of any plan on the fringe (ensuring optimality in time).

		\subsubsection{Energy}

Another popular concern in manufacturing is the energy required for a given procedure. If energy is the optimization goal, plans can be instead enqueued by the estimated total amount of energy required to execute that series of turns.


There are many ways to estimate the amount of energy required to execute a series of turns. The exact details are dependent on the fixture setup and associated motor; we present three simple models of energy estimation.

		\subsubsection{Energy - Rotation Angle}

The first estimation of energy is based on the total rotation angle. If friction in the motor bearings are the primary energy losses for the draining process, plans can be enqueued by their total absolute angle change.

This model would be appropriate if the workpiece was well balanced in a fixture that produced high energy loss due to friction.

		\subsubsection{Energy - Workpiece Center of Gravity}

Another model for energy is based on the work the motor has to perform against gravity. If the workpiece's center of gravity is positioned far away from the center of rotation, the workpiece is unbalanced in the fixture. Turns that raise the center of gravity will produce counter-torques, will turns that lower the center of gravity will produce added acceleration.

If this model is more appropriate for the fixture setup, the plans can be enqueued onto the fringe based on the integrated change in height for the center of gravity.

		\subsubsection{Energy - Acceleration And Deceleration}

Finally, if the workpiece is well balanced and friction in the rotator is low, the most appropriate model may be one based on acceleration and deceleration of the workpiece. While the total number of accelerations commonly scales with the total angle, these two properties are not necessarily the same.

In this case, plans can be enqueued based on their total acceleration change.

	\subsection{Solution Post Processing}

A full solution is defined as the sequence of gravity transitions to drain the workpiece. The graph search algorithm returns a list of gravity turns from each concave vertex to drain the workpiece; the only issue is that the $g_{end}$ from one turn rarely matches the $g_{start}$ of the following turn.

In order to rectify this situation and produce a full control sequence, our implementation contains a solution post-processor that stitches together these disparate turns and creates interpolations between one turn's $g_{end}$ and the next turn's $g_{start}$. We refer to these turns as ``setup'' turns, for they prepare the workpiece's orientation prior to the next stage of particle movement.

These ``setup'' turns never induce motion of the particle; this is because only one particle is simulated at a time and the range of vectors from $g_{end}^{t=1}$ to $g_{start}^{t=2}$ does not produce motion. The latter cause is guaranteed because a particle only settles when the terminal acceleration field $g_{end}$ points ``into'' a concave vertex. Since the $g_{start}$ of the next turn is defined as one of the outermost vectors that does not produce particle motion, a sweep from $g_{end}^{t=1}$ to $g_{start}^{t=2}$ never produces an acceleration field that induces movement of the particle.

\myfigure{width=0.7\linewidth}{setupturn}{The geometric relationship between $g_{end}^{t=1}$ and $g_{start}^{t=2}$ as it relates to the guarantee that a setup turn does not induce motion}

These ``setup'' turns can be seen during the solution animation process in our implementation which is linked in the results chapter.

					\chapter{Results \& Future Work}

\section{Online Demo}

Our implementation of this paper is available online at the following url when accessed with a modern web browser:

\vspace{0.2in}

\begin{centering}
\url{http://petercottle.com/liquidGraph/yc.html?demo}
\end{centering}

\vspace{0.2in}

\myfigure{width=0.8\linewidth}{demoFoundSolution}{A screen capture from our implementation, available online.}

This implementation includes a graphical user interface that draws the sampling at each vertex and each path segment for a particle's full simulation. It also animates the solution search process and the final result; consequently, our implementation of this algorithm runs asynchronously and is called in-between graphical frame draws.

	\subsection{Run Time}

Because our implementation is run asynchronously and performs a lot of (unnecessary) graphics processing during the solution search process, we provide both absolute time benchmarks and percentage breakdowns of CPU time between high-level functions.

The following CPU profile was collected during a solution search on a workpiece with 180 total vertices, 55 concave vertices, and 21 polygons. The solution was obtained in 14.64 seconds on a Macbook Air with a 1.86 GHz Intel Core 2 Duo and 2 GB of 1067 MHz DDR3 ram. This time, however, was obtained while a CPU profiler was running (in addition to other applications) and is not representative of the typical runtime for the algorithm.

In fact, search for the solution is rate-limited by the animation engine which runs at 60 frames per second. Consequently, all computers that are capable of completing the necessary operations between frame draws will find the solution in the same amount of time, another reason why absolute computation time is not representative of performance for our work.

The following breakdown on CPU time is provided to get a sense of the computation workload for each high-level function. CPU Self time is defined as the time spent inside the function; CPU total time is defined as the time spent inside that function and the functions called from that location.

\begin{table}[H]
\label{resultsTable}
\begin{tabular}{|c|c|c|}
\hline
CPU Self Time & CPU Total Time & Function \\ \hline
46.08\% & 46.08\% & Program (total time spent processing in Javascript) \\
20.61\% & 21.35\% & Graphical path generation \& painting \\
1.7\% & 2.8\% & Edge-Parabola intersection \\
0.63\% & 0.64\% & Quadratic equation solver \\
0.30\% & 0.30\% & Edge-Point containment test \\
0.07\% & 0.38\% & Particle sliding equation \\
0.07\% & 0.11\% & Particle collision \\
0.05\% & 3.83\% & Gravity turn sampling \\
0.03\% & 48.74\% & Graph search step \\
\hline
\end{tabular}
\caption{CPU Time breakdown for a solution search}
\end{table}

An important note here is that only 46.08\% of execution time was spent doing computation; the rest was idle time used for animation.

	\subsection{Time Complexity}

The main time-intensive aspects of this algorithm are:

\begin{itemize}
\item The intersection between a particle path and the workpiece
\item The simulation of a particle until settling
\item The simulation of different ``turns'' at each concave vertex
\item The search expansion over the workpiece.
\end{itemize}

The intersection between a particle path and the workpiece is linear in the number of edges $O(E)$ in the workpiece because each edge is intersected against a given path.

A particle's full simulation duration is dependent on the elasticity $\kappa$ which controls the rate of energy dissipation. In the best case, a particle's simulation only has one path; in the worst case, the particle never stops moving if the elasticity of the system is 1. In practice we found that most particle simulations had a number of path segments that was proportional (linearly) to the number of edges in the polgyon. Thus the simulation step is $O(E)$ with $O(E)$ intersection tests, bringing us to a total (so far) of $O(E^2).$

A full simulation is performed for every sampled turn at a given concave vertex. We restrict the number of samples to 20 in our implementation, so this step introduces a scalar constant $S$ defined as the number of samples taken at each concave vertex.

Finally, the graph search expansion over the workpiece is at worst linear in the total number of concave vertices $V_{cc}$. All together, the big order runtime is approximately

\myequation{
O(S \cdot E^2 \cdot V_{cc})
} {
	\label{eq:bigo}
}

\section{Future Work \& Discussion}

Further optimizations and improvements could be made to this work, namely to enhance the usability of the results and increase efficiency.

	\subsection{Heuristics for A* Search}

One standard improvement to uniform cost search is the addition of a consistent, admissible heuristic to convert the search into A* search. A heuristic is simply an estimation of the remaining cost from a state to the goal state. Admissibility of a heuristic requires that the heuristic never over-estimates the remaining cost, and consistency requires that the heuristic does not rapidly change values between states.

Heuristics are, by nature, very dependent on the problem they are being applied to. Many heuristics exist for positional search problems and other common search formulations; since our search formulation is rather unique, there is not as much prior work to draw from \cite{christofides1976worst}.

One initial idea for a heuristic would be to use the free-fall time from the current concave vertex to the outside of the workpiece bounding box. This essentially would be the optimistic estimation that the particle would free-fall immediately from the concave vertex at the next turn. While this heuristic would be admissible and consistent, it is also radially symmetric and does not take into account workpiece geometry. It is probable that better heuristics exist for this search formulation.

	\subsection{Bounding Box Method Adaption for Particle Path Intersections}

When intersecting rays with geometric primitives, most implementations using bounding-box methods to reduce the number of primitives tested against the ray. This bounding-box idea could be adapted to parabolic paths as well; determining which bounding boxes are needed still presents a fairly reasonable computational load, but great gains in efficiency could be made for dense workpieces with many edges.

	\subsection{Adaption to 3D - Fixed Axis}

Adapting this work to 3D polygonal meshes when the rotation axis of the workpiece is fixed is mainly an exercise in implementation. The primary difference is that parabolic paths would then need to be intersected with planes in 3D space rather than edges in 2D space.

The rest of the approach, from solution search to particle simulation, would remain the same.

	\subsection{Adaption to 3D - Free Axis}

Adapting this work to 3D polygonal meshes where the workpiece can rotate about \emph{any} rotation axis at any time presents a substantially more difficult problem. The chief obstacle here is that there is an explosion of possible turns available from any given concave vertex. The final gravity vector of the turn, $g_{end}$, could be sampled from an entire sphere rather than two small arcs in a planar circle.

There may be ways to intelligently reduce the sample space and still maintain a representative coverage of the kinetic paths attainable from a concave vertex, but much work is needed before those methods can be validated.

	\subsection{Adaption to Multiple Particles}

The adaption of this work for multiple particles is fairly trivial to do in the naive implementation. The main difference is now the state is a tuple of concave vertices, one for each particle:

\myequation{
	(V_{cc}^{1}, V_{cc}^{2}, V_{cc}^{3}, ... , V_{cc}^{n})
} {
	\label{eq:multipleParticleStateSpace}
}

Now at each state there are several sets of ``turns'' to sample from, one set for each concave vertex that contains a particle. When a turn is simulated, all other particles must be simulated as well. If any of these particles experiences scenario \#4, the entire sample has to be rejected.

The main disadvantage this naive implementation has is that now the runtime is exponential in the number of concave vertices $n$, as seen in \eqref{eq:bigo}.

\myequation{
O(S \cdot E^2 \cdot V_{cc}^{n})
} {
	\label{eq:bigoTotal}
}

Alternative methods to intelligently combine separate particles or reduce the runtime of the algorithm are likely to exist.

