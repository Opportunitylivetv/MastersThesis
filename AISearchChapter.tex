								\chapter{Solution Search}

\section{General A.I. Search}

Artificial Intelligence search is a field of study and class of algorithms that discover (or ``search'' for) plans that turn a start state into a goal state in a determinstic world. A.I. search makes heavy use of simulation to compute solutions offline before enacting those solutions in the real world.

Based on our ability to rapidly simulate water particles and the deterministic nature of the workpiece draining problem, we choose A.I. search to compute a series of rotations that fully drain a workpiece.

	\subsection{Terminology}

In order to describe how A.I. search applies to the draining problem in manufacturing, some terminology must be defined first. In order to aid our definitions, we will use a simple positional search problem as an example. Imagine a robot placed on a grid with $M$ columns and $N$ rows that is attemping to reach a goal position $G_{pos}$

\myfigure{robotGrid}{A small positional search problem.}

The ``state'' is defined as a set of information that minimally represents the current progress to the goal. For this positional search problem, the minimal state representation would be the position tuple of the robot $(R_x,R_y)$, where $R_x$ is the horizontal position of the robot and $R_y$ is the vertical position of the robot. Here these variables can take on positive integer values up to $M$ and $N$ respectively.

For every state, the agent under control has a number of actions available to take. In our example, the robot would have the actions $North$, $South$, $East$, and $West$ available to execute.

When the agent under control takes an action, a new state is produced. The ``transition function'' is responsible for transforming a state action pair into a successor state. For example, if the robot above was in position $(M = 1, N = 2)$ and took the action $North$, the transition function would return the state $(M = 1, N = 3)$.

This transition function is also responsible for performing validitiy checks against the environment. In our positional search example, the transition function would be responsible for making sure the robot does not move off the grid or into a square occupied by another agent or wall. If an invalid state action pair is given to the transition function, it often returns $null$ to designate this invalid combination.

The ``successor function'' is a meta function that uses the transition function and available actions to the agent. It is responsible for generating a list of successor states from a given state. For the above problem, the successor function would return the list of adjacent squares the robot could move into and the actions that produce those states.

A ``plan'' is simply a sequence of actions. Plans are usually maintained and updated by the successor function when exploring states. This is because while reaching the goal state determines that the search algorithm has succeeded, the sequence of actions to achieve a goal state is usually the objective of the solution.

	\subsection{General Tree Search}

These definitions are enough to implement the standard tree search algorithm.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\Function{TreeSearch}{$problem$}
	\State $queue \gets$ (initial state of $problem$, empty $plan$)

	\While{$queue$ not empty}
		\State $state, plan \gets$ REMOVE-FRONT($queue$)
		\If{Goal-Test($problem$,$state$)}
			\State \textbf{return} $plan$ \Comment{Success}
		\EndIf
		\State InsertAll($queue$, SuccessorFunction($state, plan$)) \Comment{Inserts a list of new states and plans into the queue}
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states on the queue}

\EndFunction

\end{algorithmic}
\end{algorithm}

	\subsection{Importance of Formulation}

The above definitions of state, actions, and successor functions are quite vague. This means that there are several valid formulations (or definitions) of states for a given problem. The particular formulation chosen can have large consequences on the effectiveness of A.I. search and the algorithmic runtime.


The size of the state space is the important factor when considering different problem formulations. A state space size is defined by size of the set of the different values the state could hold.

For our example above, we define the state to be the position tuple $(R_x, R_y)$. Since $R_x$ and $R_y$ can take on postive integer values up until $M$ and $N$ respectively, the size of the set of possible state values is $MN$.

While a positional search problem with one agent does not present a large (or ``expansive'') state space, these state spaces can quickly get out of control for slightly more complex problems. For instance in the general case of $l$ agents on a board of $M$ by $N$ size, the state space is defined by the list of position tuples $(R^1_x, R^1_y), (R^2_x, R^2_y)... (R^l_x, R^l_y)$. In this case the size of the state space is all possible permutations of these variables, or $(MN)^l$.

State spaces often grow exponentially large with the addition of new variables. If the state space becomes too expansive, the effectiveness of general search algorithms can be jeopardized. This is because general A.I. search has to enumerate through (or ``process'') many different states before reaching a goal state. If there are too many states to process before reaching a goal state, the algorithm may not terminate in a reasonable amount of time.

\section{Adaption of A.I. Search}

This work focuses on a traditional application of A.I. search to a novel state space formulation for workpiece draining. Our unique state formulation reduces the size of the state space to make it manageable for general A.I algorithms.

	\subsection{Traditional Formulation}

Rotating a water particle out of a workpiece can be considered a kinematic planning problem. Traditional kinematic planning problems often have state spaces that encode the kinematic properties of the object (or agent) being planned for \cite{plot}. The most common state formulation is to encode the position, velocity, and acceleration of the agent as the state formulation.

The actions available to the agent at any time are usually actions that change the acceleration on the agent. The transition function integrates this kinematic state and acceleration change in time with a pre-defined accuracy. Consequently, many transition function calls must be made to accurately integrate the path of the agent through time.

The problem with this type of state formulation is that the state space commonly becomes far too expansive for general A.I. search algorithms. For example, in a reduced problem where there are only 1000 possible position, velocity, and acceleration vectors for the state, the state space is $1000^3$. This presents far too many possible states for search algorithms to enumerate and produces an unbearable computational load.

Because of this, general A.I. search is rarely used in kinematics problems -- other techniques like kinematical motion planning are more common \cite{plot}.

	\subsection{Our State Formulation}

Our state formulation overcomes these difficulties by drastically reducing the size of the state space. We instead offload most of the computational overhead to the successor function.

The key insight here is to observe only the concave vertices of the workpiece; this insight was first used by Yusuke et all \cite{plot} in order to reduce the scope of the rotation axis discovery problem. Here it is applied to the state space formulation for the first time in order to maintain the effectiveness of general A.I. search.

We define our state as the ``settled'' position of the particle, meaning the state is either:

\begin{enumerate}
\item The concave vertex the particle is resting in, or
\item outside of the workpiece.
\end{enumerate}

By defining our state this way, we dramatically reduce the size of the state space to
$$
num(V_{cc}) + 1
$$
where $V_{cc}$ is defined as the set of concave vertices in the workpiece.

Because the maximum number of states visited is now only linear in concave vertices, our search algorithms have far fewer states to expand and a reduced computational load.

\section{Exploration}

The bulk of the computational work will now be in the successor function, which is responsible for producing the set of states that are one ``action'' away from a given input state. If a given state $S_i$ is one action away from an input state $S_j$, we define $S_i$ to be ``reachable'' from $S_j$.

	\subsection{Successor Function}

The successor function produces the list of reachable states from a given input state. For our problem, this means that the successor function will produce the set of concave vertices (or workpiece exit status) reachable from a given arbitrary concave vertex.

$$
successor(V_{cc}^{i}) = \left \{ V_{cc}^{1}, V_{cc}^{2}, ...  \right \}
$$

	\subsection{Action Definition}

The ``actions'' available to our agent will be represented by the possible set of rotations of the workpiece. In this problem we choose our frame of reference to be the workpiece geometry, so the rotation of the workpiece is observed as a rotation of the gravity vector through time.

Thus, one specific action, or ``turn'', is defined by a sweep in the gravity vector from $g_{start}$ to $g_{end}$ over a time $t_{turn}$. The interpolation function between $g_{start}$ and $g_{end}$ could take on any form, but we restrict ourselves to linear interpolation for simplicity. Likewise the total time of the turn $t_{turn}$ is similarly unbounded, but we restrict the limits of the turn time to sensible amounts for simplicity.

	\subsection{Transition Function}

In this sense, one can think of the transition function as taking in a concave vertex and defined ``turn'' and producing the settled state of the particle after that turn is simulated.

$$
trans(V_{cc}^{i}, turn_{l}) = V_{cc}^j or \qquad exit
$$

	\subsection{Possible set of Turns}

A turn is defined by three different variables: $g_{start}$, $g_{end}$, and $t_{turn}$. These variables could take on many values, which means many different turns could be produced. Consequently, a large number of actions are available to the agent at any given state, which leads to computational explosion (yet again).


In this work, we restrict the possible set of ``turns'' from a given concave vertex to reasonable limits. The main way this is accomplished is by reducing the set of gravity vectors available and fixing the duration of the turn. By doing so, we reduce the ``action space'' to something manageable which still represents the full range of kinetic possibilities.

%figure needed

First, some terminology must be defined. A given concave vertex has two leading edges $E_1$ and $E_2$ defined by outward vectors $\vec{e}_1$ and $\vec{e}_2$.

\myfigure{samplingUniform}{Pay attention the leading edges here (needs new figure).}

Our first restriction is to define $g_{start}$ as the perpendicular vectors to $\vec{e}_1$ and $\vec{e}_2$ that result in no particle motion. These vectors represent the last possible gravity direction before movement is obtained; this allows us to ``set up'' the turn slowly while the particle is still settled in the concave vertex.

%figure needed

Our second restriction is that $g_{end}$ must be a vector that produces motion of the particle while simultaenously keeping the particle on the leading edge of the concave vertex. This produces a quarter-circle range of possibilities for $g_{end}$ defined by both leading edges.

\myfigure{transitionfunctionsampling}{The possible range of gravity vectors to sample from.}

This leaves two arcs of gravity vectors. The bounds on each arc are defined by the minimal gravity vector to produce movement out of the concave vertex ($g_{\epsilon}$) and the maximum gravity vector to keep the particle on the surface ($g_{max}$).

	\subsection{Ideal Successor Function}

The ideal successor function produces the maximum set of ``reachable'' concave vertices from a given input concave vertex (and the actions to achieve those states).

Unfortunately, there are an infinite number of turns possible from each concave vertex, for $g_{end}$ can be selected from a continuous range of vectors. Clearly enumerating through every possible turn at every concave vertex is not possible.

	\subsection{Sampling}

To overcome this difficulty, we will instead sample from the continuous range of $g_{end}$ vectors and produce a limited number of turns. Each sample from this $g_{end}$ space produces a turn, which can be simulated with our transition function to produce a settled state.

Sampling from this space produces a list of defined turns (or actions). Our successor function will then examine these actions in conjunction with an input concave vertex and produce the set of reachable concave vertices.

Ideally this set of concave vertices would be identical to the set achieved by the full enumeration of the sampling space. This is not likely to happen in practice, but witt careful design we can discover the majority of this set.

	\subsection{Representative Coverage Between Limits}

The way we produce the majority of this set is to obtain a representative coverage over the possible kinetic paths out of a concave vertex. This is done by choosing a sampling method that produces the most diverse set of kinetic paths.

If the possible range of $g_{end}$ vectors is defined between the limits of $0$ and $1$, then an initial best-guess sampling function may be to use uniform sampling in the form of $x$. Because acceleration effects compound with time, this uniform sampling method produces many kinetic paths that are almost identical as can be seen in figure (BLAH).

\myfigure{samplingUniform}{The range of kinetic paths produced from 10 samples from each side at uniform sampling. Many of the sampled kinetic paths are nearly identical and thus visually appear as one.}

A far better sampling function is to use $x^3$. This function produces many samples at the low end of the range of $g_{end}$ vectors and only a few at the higher end. These low-end samples produce accelerations that are minimally different, but since acceleration effects compound with time, they produce drastically different kinetic paths as can be seen in figure (BLAH).

\myfigure{samplingCubed}{The range of kinetic paths produced from 10 samples at cubed sampling. Note the resulting kinetic paths evenly cover the space after the leading edge.}

With this sampling function, we can obtain better coverage with lower computational cost.

	\section{Complete Formulation}

Now we have all the pieces to implement A.I. search. Our state is defined as the concave vertex the particle rests in (or workpiece exit). Our successor function samples from an available range of actions to produce a reasonable set of reachable concave vertices. Simply combining these two definitions together can produce an algorithm that discovers a sequence of actions to rotate a water particle out of a workpiece.

	\subsection{Graph Search}

To further increase computational efficiency, we implement two types of graph reduction in our search.

The first is by using the standard graph implementation of our search algorithm. This graph version of the algorithm prevents a state from being expanded twice. Because the connectivity graph within workpieces often has a lot of cycles, preventing more than one expansion at each state helps considerably in cutting down computational cost.

Note how this algorithm is similar to tree search but makes use of a closed set.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\Function{UniformCostGraphSearch}{$problem,fringe$}
	\State $closed \gets$ an empty set
	\State $fringe \gets$ INSERT(MAKE-NODE(INITIAL-STATE[$problem$]),$fringe$)

	\While{$fringe$ not empty}
		\State $node \gets$ REMOVE-FRONT($fringe$)
		\If{Goal-Test($problem$,STATE[$node$])}
			\State \textbf{return} $node$ \Comment{Success}
		\EndIf
		\If{State[$node$] not in $closed$}
			\State add State[$node$] to $closed$
			\State $fringe \gets$ InsertAllByPriority(Expand($node, problem$), $fringe$)
		\EndIf
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states}

\EndFunction

\end{algorithmic}
\end{algorithm}

The second graph reduction is implemented directly in the successor function. When the successor function enumerates through the list of samples from the possible turns, it maintains a cost-sensitive closed set of concave vertices that are reachable. This set is keyed based on the ``cost'' of a transition, which in most cases is defined as the duration of the simulation.

By doing so, our successor function produces the optimal reduced set of concave vertices reachable from a given state. This graph reduction enqueues fewer plans onto the fringe, reducing the memory overhead and improving performance.

These two graph reductions excel in workpieces with finely-tesselated concave sections. Here, the connectivity graph is highly connected and contains many cycles. Without graph reductions, tree search would spend a lot of time expanding all the concave vertices over and over again.

\myfigure{hemisphereSection}{A tesselated concave section. The draining graph for a workpiece like this is highly connected and cyclic.}

\section{Cost}

The uniform cost graph search algorithm we use ensures the plan produced is optimal in cost. Our definition of cost however is very flexible and can be modified according to different manufacturing priorities.

		\subsubsection{Time}

The primary concern in manufacturing is often the processing time for a given procedure. In this case, the plans enqueued into the fringe are ordered by the total backward time to execute that plan. This ensures that when we dequeue a plan that ends in the goal, it has the lowest total time out of any plan on the fringe.

		\subsubsection{Energy}

Another popular concern in manufacturing is the energy required for a given procedure. If energy is the optimization goal, plans can be instead enqueued by the estimated total amount of energy required to execute that series of turns.


There are many ways to estimate the amount of energy required to execute a series of turns. The exact details are dependent on the fixture setup and associated motor; we present three simple models of energy estimation.

		\subsubsection{Energy - Rotation Angle}

The first estimation of energy is based on the total rotation angle. If friction in the bearings and motor are the primary energy losses for the draining process, plans can be enqueued by their total absolute angle change.

This model would be appropriate if the workpiece was well balanced in a fixture that produced high energy loss due to friction.

		\subsubsection{Energy - Workpiece Center of Gravity}

Another model for energy is based on the work the motor has to perform against gravity. If the workpiece's center of gravity is positioned far away from the center of rotation, the workpiece is unbalanced in the fixture. Turns that raise the center of gravity will produce counter-torques, will turns that lower the center of gravity will produce added acceleration.

% figure needed

If this model is more appropriate for the fixture setup, the plans can be enqueued onto the fringe based on the integrated change in height for the center of gravity.

		\subsubsection{Energy - Acceleration And Deceleration}

Finally, if the workpiece is well balanced and friction in the rotator is low, the most appropriate model may be one based on acceleration and deceleration of the workpiece. While the total number of accelerations commonly scales with the total angle, these two properties are not necessarily the same.

In this case, plans can be enqueued based on their total acceleration change.

%shitton of equations needed here

	\subsection{Solution}

		Defined as the sequence of gravity transitions from each concave vertex to produce a particle path that exits the workpiece.

\section{Control Sequence Generator}

Now that we have a solution, we need to generate a control sequence for the workpiece rotator.

	\subsection{Sample-defined Rotations}

These rotations are defined for us by the transition function.

	\subsection{Intermediary Rotations}

Between these samples we don't have anything. What we do is just interpolate between the last sample and the beginning of the next sample with a cubic bezier curve.

\section{Results}

	\subsection{Run Time}

Runs fast.

	\subsection{Part Complexity}

Transition function is constant in best case, unbounded in worst case based on the number of polygon edges.

	\subsection{Demonstration of Solution}

This paper was implemented in JavaScript, the programming language built in to most modern web-browsers. A demonstration of the algorithm finding a solution for a fairly complex part is available at 



\section{Future Work \& Discussion}

Could be improvements

	\subsection{Heuristics for A* Search}

A* search can be added with heuristics. Distance to workpiece bounding box might be a good one, but that's essentially a radially symmetric heuristic, not very informative.
