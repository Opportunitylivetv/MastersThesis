								\chapter{Solution Search}

\section{General A.I. Search}

Artificial Intelligence search is a field of study and class of algorithms that discover (or ``search'' for) plans that turn a start state into a goal state in a deterministic world. A.I. search makes heavy use of simulation to compute solutions offline before enacting those solutions in the real world.

Based on our ability to rapidly simulate water particles and the deterministic nature of the workpiece draining problem, we choose A.I. search to discover a series of rotations that fully drains a workpiece.

	\subsection{Terminology}

In order to describe how A.I. search applies to the draining problem in manufacturing, some terminology must be defined first. In order to aid our definitions, we will use a simple positional search problem as an example, shown below.

\myfigure{width=0.7\linewidth}{robotGrid}{A small positional search problem; a robot on a $M$ by $N$ grid is attempting to reach a goal position $G_{pos}$}

The ``state'' is defined as a set of information that minimally represents the current progress to the goal. For this positional search problem, the minimal state representation would be the position tuple of the robot $(R_x,R_y)$, where $R_x$ is the horizontal position of the robot and $R_y$ is the vertical position of the robot. Here these variables can take on positive integer values up to $M$ and $N$ respectively.

For every state, the agent under control has a number of actions available to take. In our example, the robot would have the actions $North$, $South$, $East$, and $West$ available to execute.

When the agent under control takes an action, a new state is produced. The ``transition function'' is responsible for transforming a state action pair into a successor state. For example, if the robot above was in state $(M = 1, N = 2)$ and took the action $North$, the transition function would return the state $(M = 1, N = 3)$.

This transition function is also responsible for performing validity checks against the environment. In our positional search example, the transition function would be responsible for making sure the robot does not move off the grid or into a square occupied by another agent or wall. If an invalid state action pair is given to the transition function, the transition function commonly returns $null$ to designate this invalid combination.

The ``successor function'' is a meta-function that uses the transition function and actions available to the agent. It is responsible for generating a list of successor states reachable (in one action) from a given state. For the above problem, the successor function would return the list of adjacent squares the robot could move into and the actions that produce those states.

A ``plan'' is simply a sequence of actions. While reaching the goal state determines that the search algorithm has succeeded, the sequence of actions to achieve a goal state is usually the objective of the solution. Consequently, plans are usually maintained and updated by the successor function when exploring states.

	\subsection{General Tree Search}

These definitions are enough to implement the standard tree search algorithm \cite{AIBook}.

\begin{algorithm}[H]\label{treeSearch}
\begin{algorithmic}[1]
\Function{TreeSearch}{$problem$}
	\State $queue \gets$ (initial state of $problem$, empty $plan$)

	\While{$queue$ not empty}
		\State $state, plan \gets$ REMOVE-FRONT($queue$)
		\If{Goal-Test($problem$,$state$)}
			\State \textbf{return} $plan$ \Comment{Success}
		\EndIf
		\State InsertAll($queue$, SuccessorFunction($state, plan$)) \Comment{Inserts a list of new states and plans into the queue}
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states on the queue}

\EndFunction

\end{algorithmic}
\caption{Standard A.I. Tree Search}
\end{algorithm}

	\subsection{Importance of Formulation}

The above definitions of state, actions, and successor functions are quite general. This means that there are several valid formulations (or definitions) of states for a given problem. The particular formulation chosen can have large consequences on the effectiveness of A.I. search and the algorithmic runtime.


The size of the state space is the important factor when considering different problem formulations. A state space size is defined by the size of the set of the different values the state could hold.

For our example above, we define the state to be the position tuple $(R_x, R_y)$. Since $R_x$ and $R_y$ can take on positive integer values up until $M$ and $N$ respectively, the size of the set of possible state values is $MN$.

While a positional search problem with one agent does not present a large (or ``expansive'') state space, these state spaces can quickly get out of control for slightly more complex problems. For instance in the general case of $l$ agents on a board of $M$ by $N$ size, the state space is defined by the list of position tuples $(R^1_x, R^1_y), (R^2_x, R^2_y)... (R^l_x, R^l_y)$. In this case the size of the state space is all possible permutations of these variables, or $(MN)^l$.

State spaces often grow exponentially large with the addition of new variables. If the state space becomes too expansive, the effectiveness of general search algorithms can be jeopardized. This is because general A.I. search has to enumerate through (or ``process'') many different states before reaching a goal state. If there are too many states to process before reaching a goal state, the algorithm may not terminate in a reasonable amount of time.

\section{Adaption of A.I. Search}

Our work focuses on a traditional application of A.I. search to a novel state space formulation for workpiece draining. Our unique state formulation reduces the size of the state space to make it manageable for general A.I algorithms.

	\subsection{Traditional Formulation}

Rotating a water particle out of a workpiece can be considered a kinematic planning problem. Traditional kinematic planning problems often have state spaces that encode the kinematic properties of the object (or agent) being planned for \cite{PlanningBook} \cite{KinematicsBook}. The most common state formulation is to encode the position, velocity, and acceleration of the agent as the state formulation.

The actions available to the agent at any time are usually actions that change the acceleration of the agent. The transition function integrates this kinematic state and acceleration change in time with a pre-defined accuracy. Consequently, many transition function calls must be made to accurately integrate the path of the agent through time.

The problem with this type of state formulation is that the state space commonly becomes far too expansive for general A.I. search algorithms. Consider a reduced problem where there are only 1000 possible position, velocity, and acceleration vectors. The size of the state space in this reduced problem is $1000^3$. This presents a large number of possible states for a search algorithm to enumerate through; the scale of this state space may even prevent the algorithm from terminating.

In kinematics problems, this type of ``traditional'' state formulation may jeopardize the entire algorithm by producing a state space that is too expansive. We present a different formulation that overcomes this obstacle.

	\subsection{Our State Formulation}

Our state formulation overcomes these difficulties by drastically reducing the size of the state space. We instead offload most of the computational overhead to the successor function.

The key insight for this state space reduction is to observe only the concave vertices of the workpiece. This insight was first used by Yasui et al. \cite{Yasui2011} in order to reduce the scope of their drainability analysis problem. Because particles cannot stick to edges and are always under the influence of gravity, particles only stop moving when they ``settle'' in a concave vertex. Consequently, any water particles placed anywhere inside the workpiece will move under the influence of gravity until they arrive at a concave vertex (or exit the workpiece).

Here this insight is instead applied to the state space formulation for the first time in order to maintain the effectiveness of general A.I. search. We define our state as the ``settled'' position of the particle, meaning the state is either:

\begin{itemize}
\item The concave vertex the particle is resting in, or
\item outside of the workpiece.
\end{itemize}

By defining our state this way, we produce a state space with size of
$$
V_{concave} + 1
$$
where $V_{concave}$ is defined as number of concave vertices in the workpiece. The size of this state space is small compared to kinetic state definitions which can be exponential in the accuracy of each value.

Because the maximum number of states visited is now only linear in concave vertices, our search algorithms have far fewer states to expand and a lower upper bound on running time.

\section{Exploration}

The bulk of the computational work will now be in the successor function, which is responsible for producing the set of states that are one ``action'' away from a given input state. If a given state $S_i$ is one action away from an input state $S_j$, we define $S_i$ to be ``reachable'' from $S_j$.

	\subsection{Successor Function}

The successor function produces the list of reachable states from a given input state. For our problem, this means that the successor function will produce the set of concave vertices (or workpiece exit status) reachable from a given concave vertex.

$$
successor(V_{c}^{i}) = \left \{ V_{c}^{l}, V_{c}^{m}, ...  \right \}
$$

	\subsection{Action Definition}

The ``actions'' available to our agent will be represented by the possible set of rotations of the workpiece. In this problem we choose our frame of reference to be the workpiece geometry, so the rotation of the workpiece is observed as a rotation of the gravity vector through time. This means that our action results in a change in the acceleration field.

More formally, we define one action (or ``turn'') as a sweep in the gravity vector from $g_{start}$ to $g_{end}$. The duration of this sweep is computed from the algorithm-wide rotation speed constant; consequently, the duration of the turn is a derived property rather than a free variable.

We restrict all turns to be less than $180^{\circ}$; consequently, the direction of the turn from $g_{start}$ to $g_{end}$ is then implied. The interpolation function between $g_{start}$ and $g_{end}$ could take on any form, but we restrict ourselves to linear interpolation for simplicity.

	\subsection{Transition Function}

Now we have fully defined both elements for the transition function; the states are concave vertices and the actions available to the agent are specific turns.

Consequently, the transition function is then defined as a function that takes in a concave vertex and a turn; it produces the settled state of the particle after simulation.

$$
transition(V_{c}^{i}, turn(g_{start}, g_{end}) = V_{c}^n \qquad or \qquad exit
$$

	\subsection{Possible set of Turns}

A turn is defined by two different variables: $g_{start}$ and $g_{end}$. These variables could take on many values which means many different turns can be defined. Consequently, a large number of actions are available to the agent at any given state which leads to computational explosion (yet again).

In this work, we reduce the possible set of ``turns'' from a given concave vertex to within reasonable limits. This is accomplished by reducing the set of gravity vectors available from which turns are defined.

Ideally, we reduce the space of all possible actions to something ``manageable'' which still represents the full range of kinetic possibilities. An action or state space is ``manageable'' if it does not jeopardize termination of the algorithm.

To understand how the set of gravity vectors is reduced, some terminology must first be defined. A given concave vertex has two incident edges $E_1$ and $E_2$ defined by outward vectors $\vec{e}_1$ and $\vec{e}_2$.

\myfigure{width=0.5\linewidth}{edgeDefinition}{A concave vertex $V_{c}^1$ and its two corresponding outward edge vectors $\vec{e}_1$ and $\vec{e}_2$}

We start with a full Gaussian circle of possibilities to sample $g_{start}$ and $g_{end}$ from, as illustrated in Figure \ref{restriction1}.

\myfigure{width=0.8\linewidth}{restriction1}{The initial set of possible vectors to sample $g_{start}$ and $g_{end}$ from.}

We first restrict the possible values of $g_{start}$. We define $g_{start}$ as a vector that does not produce motion of the particle but is as close as possible to producing motion.

If $g_{start}$ satisfies these two conditions, two benefits arise. The first is that if $g_{start}$ does not induce motion of the particle, a turn that ends in $g_{start}$ does not require simulation once the turn ends. This will be greatly useful for our solution post-processor. The second benefit is that any turn defined with $g_{start}$ spends the maximum amount of time inducing motion of the particle.

There are only two vectors that satisfy these two conditions -- the perpendicular vectors to $\vec{e}_1$ and $\vec{e}_2$ that point into the workpiece, denoted as $\vec{e}_1^p$ and $\vec{e}_2^p$ in Figure \ref{restriction2}.

\myfigure{width=0.8\linewidth}{restriction2}{$g_{start}$ is reduced to one of the two perpendicular vectors}

Our second restriction is that $g_{end}$ must be a vector that produces motion of the particle while simultaneously keeping the particle on either incident of the edges of the concave vertex. This produces two quarter-circle segments of possibilities for $g_{end}$, each of which are defined by a incident edge and the perpendicular vector to that edge as illustrated in Figure \ref{restriction3}.


\myfigure{width=0.8\linewidth}{restriction3}{$g_{end}$ is reduced to vectors that produce motion while keeping the particle on the incident edge}

This leaves two arcs of gravity vectors from which $g_{end}$ can be selected. Note that once $g_{start}$ is selected, $g_{end}$ is selected from the arc of vectors that borders $g_{start}$ in order to produce turns that maximize motion of the particle.

	\subsection{Ideal Successor Function}

The ideal successor function produces the set of all ``reachable'' concave vertices from a given input concave vertex (and the actions to achieve those states).

Unfortunately there are an infinite number of turns possible from each concave vertex, since $g_{end}$ can be selected from a continuous range of vectors. Clearly enumerating through every possible turn at every concave vertex is not possible.

	\subsection{Sampling}

To overcome this difficulty, we will instead sample from the continuous range of $g_{end}$ vectors and produce a finite number of turns. Ideally the set of concave vertices produced by these sampled turns would be identical to the set achieved by the full enumeration of the sampling space. This is not likely to happen in practice, but with careful design we can discover the majority of this set.

%Each sample from the $g_{end}$ space produces a turn which can be simulated with our transition function to produce a settled state. These turns are the actions available to our agent. Our successor function will then examine these actions in conjunction with an input concave vertex and produce the set of reachable concave vertices.

	\subsection{Representative Coverage Between Limits}

The way we produce the majority of this set is to obtain a representative coverage over the possible kinetic paths out of a concave vertex. This is done by choosing a sampling method that produces the most diverse set of kinetic paths.

If the possible range of $g_{end}$ vectors is defined between the limits of $0$ and $1$ and our interpolation function $f(x)$ is a function of this progress variable $x$, then an initial best-guess sampling function might be to use uniform sampling:

$$
f(x) = x.
$$

With this sampling function, turns are selected uniformly between the limits of $g_{end}$. This sampling function unfortunately does not produce a uniform distribution of kinetic paths. This is primarily because acceleration effects compound with time; uniform sampling produces many kinetic paths that are almost identical. This is illustrated in Figure \ref{samplingUniform}.

\myfigure{width=0.5\linewidth}{samplingUniform}{The range of kinetic paths produced from 10 per side with uniform sampling. Many of the sampled kinetic paths are nearly identical and thus visually appear as one.}

A far better sampling function is to use cubic sampling:

$$
f(x) = x^3.
$$

This function produces many samples near the lower bound of $g_{end}$ vectors and only a few samples near the upper bound. These low-end samples produce accelerations that are minimally different, but since acceleration effects compound with time, they produce drastically different kinetic paths. This is illustrated in Figure \ref{samplingCubed}.

\myfigure{width=0.5\linewidth}{samplingCubed}{The range of kinetic paths produced from 6 samples per side with cubed sampling. Note the resulting kinetic paths evenly cover the space after the incident edge.}

With this sampling function, we can obtain better coverage with lower computational cost.

	\section{Complete Formulation}

Now we have all the pieces to implement A.I. search. Our state is defined as the concave vertex the particle rests in (or workpiece exit). Our successor function samples from an available range of actions to produce a representative set of reachable concave vertices. Simply combining these two definitions together can produce an algorithm that discovers a sequence of actions to rotate a water particle out of a workpiece.

We now present two modifications to general A.I. search to enhance performance.

	\subsection{Uniform Cost Graph Search}

The first search modification is to switch to the standard graph implementation of our search algorithm; this effectively converts tree search (detailed in Algorithm 1) into graph search \cite{AIBook}. This graph version of the algorithm prevents a state from being expanded twice \cite{AIBook}. Because the connectivity graph within workpieces often has many cycles \cite{Yasui2011}, preventing more than one expansion from each state helps considerably in cutting down computational cost.

Furthermore, we use the ``uniform cost'' version of graph search \cite{AIBook} to ensure that the solution discovered is optimal in cost. This is accomplished by enqueueing partial plans onto the priority queue by their associated cost, as detailed in Algorithm 2.

\begin{algorithm}[H]\label{graphSearch}
\begin{algorithmic}[1]
\Function{UniformCostGraphSearch}{$problem,fringe$}
	\State $closed \gets$ an empty set
	\State $fringe \gets$ Insert(Make-Node(Initial-State[$problem$]),$fringe$)

	\While{$fringe$ not empty}
		\State $node \gets$ Remove-Front($fringe$)
		\If{Goal-Test($problem$,State[$node$])}
			\State \textbf{return} $node$ \Comment{Success}
		\EndIf
		\If{State[$node$] not in $closed$}
			\State add State[$node$] to $closed$
			\State $fringe \gets$ InsertAllByPriority(Expand($node, problem$), $fringe$)
		\EndIf
	\EndWhile
	\State \textbf{return} $failure$ \Comment{Failure from exhausting all states}

\EndFunction

\end{algorithmic}
\caption{Uniform Cost Graph Search}
\end{algorithm}

	\subsection{Optimal Actions}

The second search modification is implemented directly in the successor function. By definition, the successor function returns a set of ``reachable'' states; each state is paired with a list of associated actions to transition to that state. Normally during search, every one of these associated actions generates a new plan that is placed in the priority queue.

Our optimization here is simply to return a single optimal action that produces a state, rather than a list of arbitrary actions. This results in fewer plans enqueued onto the fringe while maintaining optimality.

This is accomplished by placing actions into a cost-sensitive closed set \cite{AIBook}. A cost-sensitive set behaves like a normal set; the only difference is that each entry is keyed by a ``cost'' variable. When inserting a new item, that item will be inserted into the set if it does not already exist \emph{or} if it has a cost that is lower than the existing member.

By using this slightly different data structure, our successor function produces the same set of reachable states, but now each state is paired with am optimal action.

\section{Cost}

The uniform cost graph search algorithm we use ensures the plan produced is optimal in cost. This is because the goal check for a partial plan is performed after the plan is dequeued from the priority queue. When a partial plan is dequeued from a priority queue that is ranked by cost, we are guaranteed that no other plan has a lower cost. This guarantee of optimality is the foundation of uniform cost and A* search \cite{AIBook}.

Our definition of cost however is very flexible and can be modified according to different manufacturing priorities.

		\subsection{Time}

The primary concern in manufacturing is often the processing time for a given procedure. In this case, the plans enqueued into the fringe are ordered by the time needed to execute that plan. This total time includes the sum of all turn durations as well as the time needed to wait for particles to settle. Enqueuing plans by this value ensures that when we dequeue a plan that ends in the goal, it has the lowest total time out of any plan on the fringe (ensuring optimality in time).

		\subsection{Energy}

Another concern in manufacturing is the energy required for a given procedure. If energy is the optimization goal, plans can be instead enqueued by the estimated total amount of energy required to execute that series of turns.


There are many ways to estimate the amount of energy required to execute a series of turns. The exact details are dependent on the fixture setup and associated motor; we present three simple models of energy estimation.

		\subsubsection{Energy - Total Rotation Angle}

The first estimation of energy is based on the total rotation angle. If friction in the motor bearings is the primary cause of energy loss for the draining process, plans can be enqueued by their total absolute angle change.

This model would be appropriate if the workpiece was well balanced in a fixture that produced high energy loss due to friction.

		\subsubsection{Energy - Workpiece Center of Gravity}

Another model for energy is based on the work the motor has to perform against gravity. If the workpiece's center of gravity is positioned far away from the center of rotation, the workpiece is unbalanced in the fixture. Turns that raise the center of gravity will produce counter-torques, whereas turns that lower the center of gravity will produce added acceleration.

If this model is more appropriate for the fixture setup, the plans can be enqueued onto the fringe based on the integrated change in height for the center of gravity.

		\subsubsection{Energy - Acceleration And Deceleration}

Finally, if the workpiece is well balanced and friction in the rotator is low, the majority of energy loss will be due to acceleration and deceleration of the workpiece. In this case, the most appropriate model for energy cost may be one based on the total number of turns in the plan.

This contrasts with the energy model of total angle; while the total number of turns in a plan commonly scales with the total angle of a plan, these two properties are not necessarily the same.

		\subsubsection{Our Implementation}

Our implementation of this paper (described further in Chapter \ref{results}) uses time as the cost function during solution search. This is primarily an interaction design decision; users are more likely to sense optimality in time over other possible cost functions.

	\subsection{Solution Post Processing}

A full solution is defined as the sequence of gravity transitions to drain the workpiece. The graph search algorithm returns a list of gravity turns from each concave vertex to drain the workpiece; the only issue is that the $g_{end}$ from one turn rarely matches the $g_{start}$ of the following turn.

In order to rectify this situation and produce a full control sequence, our implementation contains a solution post-processor that stitches together these disparate turns and creates interpolations between one turn's $g_{end}$ and the next turn's $g_{start}$. We refer to these turns as ``setup'' turns, for they transition the workpiece's orientation from the previous action ($A=i$) to the beginning of the next action ($A=i + 1$). These ``setup'' turns can be seen during the solution animation process in our implementation which is linked in the results chapter.

These ``setup'' turns never induce motion of the particle; this is because only one particle is simulated at a time and the range of vectors from $g_{end}^{A=i}$ to $g_{start}^{A=i + 1}$ does not produce motion.

We arrive at this guarantee with the following reasoning. A particle only settles when the terminal acceleration field $g_{end}$ points ``into'' a concave vertex. Since the $g_{start}$ of the next turn is defined as one of the outermost vectors that \emph{also} does not produce particle motion, a sweep from $g_{end}^{A=i}$ to $g_{start}^{A=i + 1}$ never produces an acceleration that induces movement of the particle. This guarantee is illustrated in Figure \ref{setupturn}.

When simulating multiple particles, this guarantee no longer holds. We present a further reduction of the action space in Chapter \ref{multipleExtension} to restore this guarantee when working with multiple particles.

\myfigure{width=0.7\linewidth}{setupturn}{The geometric relationship between $g_{end}^{A=i}$ and $g_{start}^{A=i + 1}$ as it relates to the guarantee that a setup turn does not induce motion}

  \section{Time Complexity}\label{timeComplexity}

Now that the entire search algorithm has been defined, we can analyze the time complexity of each subroutine. The most time complex components of our approach are:

\begin{itemize}
\item the intersection between a particle path and the workpiece,
\item the simulation of a particle until settling,
\item the search expansion for a particular state, and
\item the overall search for a solution.
\end{itemize}

We start with the intersection between a particle and the workpiece -- our fundamental unit of computation. The intersection between a particle path and the workpiece is linear in the number of edges in the workpiece $e$, since each edge in the workpiece is intersected against a test path.

Next, the simulation of a single particle continues until the particle settles in a given location. Each time a particle collides with a surface, it obtains a new kinetic state and resulting parabola. This new parabola then needs to be intersected against the workpiece; consequently, the time complexity of particle simulation is determined by the number of collisions the particle experiences before settling.

The number of collisions for a given particle simulation is not easily bounded; if the elasticity of the system $\kappa$ is 1, the particle could never settle in a concave vertex depending on the geometry of the workpiece. The best case lower bound is when a particle's simulation terminates after one collision or immediately exits the workpiece.

In practice we found that most particles had a number of collisions that was proportional (linearly) to the number of edges in the polygon $e$. We cannot however theoretically bound the time complexity of the particle simulation step.

If a particle were to collide with each of the $e$ edges in the workpiece once during simulation, there would be $e^2$ total intersection tests for a single particle simulation.

Next, the search expansion for a state results in many particle simulations. The exact number is specified by $c_1$, the user-specified number of samples per state. If each particle simulation involves $e^2$ intersection tests, an expansion from a given state results in $c_1 \cdot e^2$ intersection tests.

Finally, the time complexity of the entire solution search must be analyzed. The state space of our formulation has a size of $V_{concave} + 1$. In the worst case scenario of solution search, the algorithm must explore every possible state. If each state expansion requires $c_1 \cdot e^2$ intersection tests, the entire algorithm requires:

\myequation{
	c_1 \cdot e^2 \cdot	V_{concave}
} {
	\label{eq:bigo}
}

intersection tests.

Note that Equation \eqref{eq:bigo} provides a meaningful upper-bound on the number of intersection tests that must be performed during solution search with only one core assumption -- every particle simulation produces a path that collides with each edge of the workpiece once. The actual behavior of particle simulation may involve far fewer collisions.
